n <- 100  # sample size
X <- cbind(1, rnorm(n), rnorm(n))  # Two regressors plus intercept
beta_true <- c(1, 2, -1)           # True parameters
epsilon <- rnorm(n, 0, 0.5)        # Error term
y <- X %*% beta_true + epsilon     # Generate dependent variable (Y = Xβ + ε)
# Manual OLS implementation using matrix algebra
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% y # beta_hat = (X'X)^-1 X'y
y_hat <- X %*% beta_hat
residuals <- y - y_hat
# Compare with lm()
model_lm <- lm(y ~ X[,-1])  # exclude first column (intercept) because lm() adds it automatically
# Display results
cat("Manual OLS coefficients:\n")
print(beta_hat)
cat("\nlm() coefficients:\n")
print(coef(model_lm))
# Calculate R-squared manually
TSS <- sum((y - mean(y))^2)
RSS <- sum(residuals^2)
R_squared_manual <- 1 - RSS/TSS
cat("\nManual R-squared:", R_squared_manual)
cat("\nlm() R-squared:", summary(model_lm)$r.squared)
# Create plotting data for first regressor
plot_data <- data.frame(
x = X[,2],  # first regressor
y = y,
fitted = y_hat
)
# Sort for clean plotting
plot_data <- plot_data[order(plot_data$x),]
# Plot
plot(plot_data$x, plot_data$y,
main = "Regression Results",
xlab = "First Regressor",
ylab = "y",
pch = 16,
col = "grey50")
lines(plot_data$x, plot_data$fitted,
col = "red",
lwd = 2)
legend("topleft",
legend = c("Observed", "Fitted"),
pch = c(16, NA),
lty = c(NA, 1),
col = c("grey50", "red"))
if (!require("plotly")) {
install.packages("plotly")
}
library(plotly)
# Create the surface data
x.pred <- seq(min(X[,2]), max(X[,2]), length.out = 30)
y.pred <- seq(min(X[,3]), max(X[,3]), length.out = 30)
xy <- expand.grid(x = x.pred, y = y.pred)
z.pred <- cbind(1, xy$x, xy$y) %*% beta_hat
z.pred <- matrix(z.pred, nrow = length(x.pred))
# Create the 3D plot with adjusted orientation
plot_ly() %>%
add_surface(x = x.pred,
y = y.pred,
z = z.pred,
opacity = 0.7,
colorscale = list(c(0, 1), c("rgb(200,200,255)", "rgb(0,0,255)")),
name = "Fitted Surface") %>%
add_trace(x = X[,2],
y = X[,3],
z = as.vector(y),
type = 'scatter3d',
mode = 'markers',
marker = list(size = 3,
color = 'red',
opacity = 0.8),
name = "Observed Data") %>%
layout(scene = list(
xaxis = list(title = "First Regressor", autorange = "reversed"),
yaxis = list(title = "Second Regressor"),
zaxis = list(title = "y"),
camera = list(
eye = list(x = -1.5, y = 1.5, z = 1.5)
)),
title = "Interactive 3D Visualization of Multiple Regression")
# Simulate a multiple regression with two regressors:
set.seed(123)
n <- 100
# X includes an intercept column plus two random regressors
X <- cbind(1, rnorm(n), rnorm(n))
beta_true <- c(1, 2, -1)  # True coefficients: intercept, beta1, beta2
epsilon <- rnorm(n, mean = 0, sd = 0.5)
y_multi <- X %*% beta_true + epsilon  # Model: y = Xβ + error
# Manual OLS estimation using matrix algebra: β_hat = (X'X)^{-1} X'y
beta_hat_manual <- solve(t(X) %*% X) %*% t(X) %*% y_multi
y_hat_manual <- X %*% beta_hat_manual
residuals_manual <- y_multi - y_hat_manual
# Fit the same model using lm()
# Note: lm() adds the intercept automatically, so we exclude the first column of X.
multi_model <- lm(y_multi ~ X[, -1])
cat("Manual OLS (Multiple Regression):\n")
print(beta_hat_manual)
cat("\nCoefficients from lm():\n")
print(coef(multi_model))
# Calculate R-squared manually
TSS <- sum((y_multi - mean(y_multi))^2)
RSS <- sum(residuals_manual^2)
R2_manual <- 1 - RSS / TSS
cat("\nManual R-squared:", R2_manual, "\n")
cat("lm() R-squared:", summary(multi_model)$r.squared, "\n")
# Create matrices in different ways
A <- matrix(1:6, nrow = 2, ncol = 3)
B <- matrix(c(1, 2, 3, 4), nrow = 2)  # 2 x 2 matrix
C <- rbind(c(1, 2, 3), c(4, 5, 6))     # Using row binding
D <- cbind(c(1, 2), c(3, 4))            # Using column binding
I <- diag(2)                           # Identity matrix 2x2
# Print matrices and basic properties
cat("Matrix A:\n")
print(A)
cat("\nMatrix B:\n")
print(B)
cat("\nIdentity Matrix (I):\n")
print(I)
cat("\nDimensions of A:", dim(A), "\n")
cat("Number of rows in A:", nrow(A), "\n")
cat("Number of columns in A:", ncol(A), "\n")
# Matrix arithmetic examples
cat("\nB + B:\n")
print(B + B)
cat("\nB - B:\n")
print(B - B)
cat("\nMatrix multiplication (B %*% B):\n")
print(B %*% B)
cat("\nElement-wise multiplication (B * B):\n")
print(B * B)
# Transpose and inverse of B
cat("\nTranspose of B:\n")
print(t(B))
cat("\nInverse of B:\n")
B_inv <- solve(B)
print(B_inv)
cat("\nB multiplied by its inverse (should approximate I):\n")
print(round(B %*% B_inv, 10))
# Quick quiz:
# - Create a 4x4 matrix with values drawn from a random uniform distribution with range [-2, 5].
# - Create a 4x1 vector with four values drawn from a random standard normal distribution.
# - Multiply these two and print out the result using cat().
my_matrix <- matrix(runif(16, -2, 5), nrow=4, ncol=4)
my_vector <- rnorm(4, 0, 1)
cat("Result = ", my_matrix %*% my_vector)
# Quick quiz:
# - Create a 4x4 matrix with values drawn from a random uniform distribution with range [-2, 5].
# - Create a 4x1 vector with four values drawn from a random standard normal distribution.
# - Multiply these two and print out the result using cat().
my_matrix <- matrix(runif(16, -2, 5), nrow=4, ncol=4)
my_vector <- rnorm(4, 0, 1)
cat("Result = ", my_matrix %*% t(my_vector))
cat("Result = ", my_matrix %*% my_vector)
cat("Result = ", my_matrix %*% my_vector)
cat("Result = ", t(my_vector) %*% my_matrix)
assertCondition(my_matrix %*% my_vector == t(my_vector) %*% my_matrix)
try {
try (
assertCondition(my_matrix %*% my_vector == t(my_vector) %*% my_matrix, .exprString = "The two results are not equal.")
)
my_matrix %*% my_vector %assert% t(my_vector) %*% my_matrix
assertCondition(sqrt("abc"), "error")
my_matrix %*% my_vector == t(my_vector) %*% my_matrix
plot(residuals_manual)
hline(y=0)
# Quick Quiz:
# - Simulate your Data Generating Process with an intercept and two regressors
# - Estimate the three coefficients and the residuals with the OLS estimator manually
# - Plot the residuals
plot(residuals_manual)
hline(y=0)
# Quick Quiz:
# - Simulate your Data Generating Process with an intercept and two regressors
# - Estimate the three coefficients and the residuals with the OLS estimator manually
# - Plot the residuals
plot(residuals_manual)
abline(y=0)
# Quick Quiz:
# - Simulate your Data Generating Process with an intercept and two regressors
# - Estimate the three coefficients and the residuals with the OLS estimator manually
# - Plot the residuals
plot(residuals_manual)
abline(h=0, col="red")
# Install and load necessary packages
if (!require("fredr")) {
install.packages("fredr")
library(fredr)
} else {
library(fredr)
}
if (!require("dplyr")) {
install.packages("dplyr")
library(dplyr)
}
fredr_set_key("aeca492c1d6b24a773fe1fb915779b96") # Replace with your own key from https://cran.r-project.org/web/packages/fredr/vignettes/fredr.html
# Define the observation period
start_date <- as.Date("2015-01-01")
end_date <- as.Date("2020-12-31")
# Download monthly data from FRED
data_PCEC <- fredr(series_id = "PCEC", observation_start = start_date, observation_end = end_date)
data_M2SL <- fredr(series_id = "M2SL", observation_start = start_date, observation_end = end_date)
data_FEDFUNDS <- fredr(series_id = "FEDFUNDS", observation_start = start_date, observation_end = end_date)
# For merging, create a "year-month" column. PCEC and M2SL are monthly; for FEDFUNDS (often daily),
# we aggregate to the monthly average.
data_PCEC <- data_PCEC %>% mutate(year_month = format(date, "%Y-%m"))
data_M2SL <- data_M2SL %>% mutate(year_month = format(date, "%Y-%m"))
data_FEDFUNDS <- data_FEDFUNDS %>% mutate(year_month = format(date, "%Y-%m"))
monthly_FEDFUNDS <- data_FEDFUNDS %>%
group_by(year_month) %>%
summarize(FEDFUNDS = mean(value, na.rm = TRUE))
# Merge the datasets by "year_month"
merged_data <- merge(
data_PCEC[, c("year_month", "value")],
data_M2SL[, c("year_month", "value")],
by = "year_month", suffixes = c("_PCEC", "_M2SL")
)
merged_data <- merge(merged_data, monthly_FEDFUNDS, by = "year_month")
# Rename columns for clarity
names(merged_data) <- c("year_month", "PCEC", "M2SL", "FEDFUNDS")
head(merged_data)
# Convert series to numeric if necessary
merged_data$PCEC <- as.numeric(merged_data$PCEC)
merged_data$M2SL <- as.numeric(merged_data$M2SL)
merged_data$FEDFUNDS <- as.numeric(merged_data$FEDFUNDS)
# Manual OLS using matrix algebra for the FRED data example:
# Model: PCEC = β0 + β1*M2SL + β2*FEDFUNDS + error
n_obs <- nrow(merged_data)
X_fred <- cbind(1, merged_data$M2SL, merged_data$FEDFUNDS)  # Design matrix (with intercept)
y_fred <- merged_data$PCEC
beta_hat_fred_manual <- solve(t(X_fred) %*% X_fred) %*% t(X_fred) %*% y_fred
y_hat_fred_manual <- X_fred %*% beta_hat_fred_manual
residuals_fred_manual <- y_fred - y_hat_fred_manual
# Fit the same model using lm()
fred_model <- lm(PCEC ~ M2SL + FEDFUNDS, data = merged_data)
cat("Manual OLS Coefficients (FRED data):\n")
print(beta_hat_fred_manual)
cat("\nCoefficients from lm() (FRED data):\n")
print(coef(fred_model))
# Residual vs. Fitted Plot for the FRED model
plot(fred_model$fitted.values, fred_model$residuals,
main = "Residuals vs. Fitted Values",
xlab = "Fitted Values", ylab = "Residuals",
pch = 20, col = "blue")
abline(h = 0, lty = 2, col = "red")
# Q-Q Plot for the residuals
qqnorm(fred_model$residuals, main = "Normal Q-Q Plot")
qqline(fred_model$residuals, col = "red")
# Install and load lmtest package if not already installed
if (!require("lmtest")) {
install.packages("lmtest")
library(lmtest)
} else {
library(lmtest)
}
# Breusch-Pagan Test for homoscedasticity
bp_test <- bptest(fred_model)
cat("Breusch-Pagan Test for Homoscedasticity:\n")
print(bp_test)
# Durbin-Watson Test for autocorrelation
dw_test <- dwtest(fred_model)
cat("\nDurbin-Watson Test for Autocorrelation:\n")
print(dw_test)
# Shapiro-Wilk Test for normality of residuals
shapiro_test <- shapiro.test(fred_model$residuals)
cat("\nShapiro-Wilk Test for Normality of Residuals:\n")
print(shapiro_test)
# Convert series to numeric if necessary (just a sanity check)
merged_data$PCEC <- as.numeric(merged_data$PCEC)
merged_data$M2SL <- as.numeric(merged_data$M2SL)
merged_data$FEDFUNDS <- as.numeric(merged_data$FEDFUNDS)
# Manual OLS using matrix algebra for the FRED data example:
# Model: PCEC = β0 + β1*M2SL + β2*FEDFUNDS + error
n_obs <- nrow(merged_data)
X_fred <- cbind(1, merged_data$M2SL, merged_data$FEDFUNDS)  # Intercept + Data
y_fred <- merged_data$PCEC
beta_hat_fred_manual <- solve(t(X_fred) %*% X_fred) %*% t(X_fred) %*% y_fred
y_hat_fred_manual <- X_fred %*% beta_hat_fred_manual
residuals_fred_manual <- y_fred - y_hat_fred_manual
# Fit the same model using lm()
fred_model <- lm(PCEC ~ M2SL + FEDFUNDS, data = merged_data)
cat("Manual OLS Coefficients (FRED data):\n")
print(beta_hat_fred_manual)
cat("\nCoefficients from lm() (FRED data):\n")
print(coef(fred_model))
# Partial regression plot for M2SL:
# Regress PCEC on FEDFUNDS (excluding M2SL)
model_y_FED <- lm(PCEC ~ FEDFUNDS, data = merged_data)
resid_y_M2 <- residuals(model_y_FED)
# Regress M2SL on FEDFUNDS
model_M2_FED <- lm(M2SL ~ FEDFUNDS, data = merged_data)
resid_x_M2 <- residuals(model_M2_FED)
# Plot the residuals
plot(resid_x_M2, resid_y_M2,
main = "Partial Regression Plot for M2SL (Money Supply)",
xlab = "Residuals of M2SL ~ FEDFUNDS",
ylab = "Residuals of PCEC ~ FEDFUNDS",
pch = 20, col = "blue")
abline(lm(resid_y_M2 ~ resid_x_M2), col = "red", lwd = 2)
slope_M2 <- coef(lm(resid_y_M2 ~ resid_x_M2))[2]
legend("topleft", legend = paste("Slope =", round(slope_M2, 3)), bty = "n")
# Partial regression plot for FEDFUNDS:
# Regress PCEC on M2SL (excluding FEDFUNDS)
model_y_M2 <- lm(PCEC ~ M2SL, data = merged_data)
resid_y_FED <- residuals(model_y_M2)
# Regress FEDFUNDS on M2SL
model_FED_M2 <- lm(FEDFUNDS ~ M2SL, data = merged_data)
resid_x_FED <- residuals(model_FED_M2)
# Plot the residuals
plot(resid_x_FED, resid_y_FED,
main = "Partial Regression Plot for FEDFUNDS (Fed Funds Rate)",
xlab = "Residuals of FEDFUNDS ~ M2SL",
ylab = "Residuals of PCEC ~ M2SL",
pch = 20, col = "blue")
abline(lm(resid_y_FED ~ resid_x_FED), col = "red", lwd = 2)
slope_FED <- coef(lm(resid_y_FED ~ resid_x_FED))[2]
legend("topleft", legend = paste("Slope =", round(slope_FED, 3)), bty = "n")
# Create matrices in different ways
A <- matrix(1:6, nrow = 2, ncol = 3)
A
cat("\nDimensions of A:", dim(A), "\n")
# Create matrices in different ways
A <- matrix(1:6, nrow = 2, ncol = 3)
B <- matrix(c(1, 2, 3, 4), nrow = 2)  # 2 x 2 matrix
C <- rbind(c(1, 2, 3), c(4, 5, 6))     # Using row binding
D <- cbind(c(1, 2), c(3, 4))            # Using column binding
I <- diag(2)                           # Identity matrix 2x2
# Print matrices and basic properties
cat("Matrix A:\n")
print(A)
cat("\nMatrix B:\n")
print(B)
cat("\nIdentity Matrix (I):\n")
print(I)
cat("\nDimensions of A:", dim(A), "\n")
cat("Number of rows in A:", nrow(A), "\n")
cat("Number of columns in A:", ncol(A), "\n")
# Matrix arithmetic examples
cat("\nB + B:\n")
print(B + B)
cat("\nB - B:\n")
print(B - B)
cat("\nMatrix multiplication (B %*% B):\n")
print(B %*% B)
cat("\nElement-wise multiplication (B * B):\n")
print(B * B)
# Transpose and inverse of B
cat("\nTranspose of B:\n")
print(t(B))
cat("\nInverse of B:\n")
B_inv <- solve(B) # check the documentation for solve() using the Help tab
print(B_inv)
cat("\nB multiplied by its inverse (should approximate I):\n")
print(round(B %*% B_inv, 10))
# Quick quiz:
# - Set a seed so you can replicate the exercise.
# - Create a 4x4 matrix with values drawn from a random uniform distribution with range [-2, 5].
# - Create a 4x1 vector with four values drawn from a random standard normal distribution.
# - Multiply these two and print out the result using cat().
set.seed(1234)
a <- matrix(runif(16, -2, 5), nrow=4, ncol=4)
b <- rnorm(4, 0, 1)
a %*% b
# Simulate a multiple regression with two regressors:
set.seed(123)
n <- 100
# X includes an intercept column plus two random regressors
X <- cbind(1, rnorm(n), rnorm(n))
beta_true <- c(1, 2, -1)  # True coefficients: intercept, beta1, beta2
epsilon <- rnorm(n, mean = 0, sd = 0.5)
y_multi <- X %*% beta_true + epsilon  # Model: y = Xβ + error
# Manual OLS estimation using matrix algebra: β_hat = (X'X)^{-1} X'y
beta_hat_manual <- solve(t(X) %*% X) %*% t(X) %*% y_multi
y_hat_manual <- X %*% beta_hat_manual
residuals_manual <- y_multi - y_hat_manual
# Fit the same model using lm()
# Note: lm() adds the intercept automatically, so we exclude the first column of X.
multi_model <- lm(y_multi ~ X[, -1])
cat("Manual OLS (Multiple Regression):\n")
print(beta_hat_manual)
cat("\nCoefficients from lm():\n")
print(coef(multi_model))
# Calculate R-squared manually
TSS <- sum((y_multi - mean(y_multi))^2)
RSS <- sum(residuals_manual^2)
R2_manual <- 1 - RSS / TSS
cat("\nManual R-squared:", R2_manual, "\n")
cat("lm() R-squared:", summary(multi_model)$r.squared, "\n")
summary(multi_model)
# Quick Quiz:
# - Simulate your Data Generating Process with an intercept and two regressors
# - Estimate the three coefficients and the residuals with the OLS estimator manually
# - Plot the residuals using plot() with a red horizontal line at 0 using abline()
set.seed(123)
n <- 100
# X includes an intercept column plus two random regressors
X <- cbind(1, rnorm(n), rnorm(n))
beta_true <- c(1, 2, -1)  # True coefficients: intercept, beta1, beta2
epsilon <- rnorm(n, mean = 0, sd = 0.5)
y_multi <- X %*% beta_true + epsilon  # Model: y = Xβ + error
# Manual OLS estimation using matrix algebra: β_hat = (X'X)^{-1} X'y
beta_hat_manual <- solve(t(X) %*% X) %*% t(X) %*% y_multi
y_hat_manual <- X %*% beta_hat_manual
residuals_manual <- y_multi - y_hat_manual
plot(residuals_manual)
abline(h=0)
# Quick Quiz:
# - Simulate your Data Generating Process with an intercept and two regressors
# - Estimate the three coefficients and the residuals with the OLS estimator manually
# - Plot the residuals using plot() with a red horizontal line at 0 using abline()
set.seed(123)
n <- 100
# X includes an intercept column plus two random regressors
X <- cbind(1, rnorm(n), rnorm(n))
beta_true <- c(1, 2, -1)  # True coefficients: intercept, beta1, beta2
epsilon <- rnorm(n, mean = 0, sd = 0.5)
y_multi <- X %*% beta_true + epsilon  # Model: y = Xβ + error
# Manual OLS estimation using matrix algebra: β_hat = (X'X)^{-1} X'y
beta_hat_manual <- solve(t(X) %*% X) %*% t(X) %*% y_multi
y_hat_manual <- X %*% beta_hat_manual
residuals_manual <- y_multi - y_hat_manual
plot(residuals_manual)
abline(h=0, col="red")
# Quick Quiz:
# - Simulate your Data Generating Process with an intercept and two regressors
# - Estimate the three coefficients and the residuals with the OLS estimator manually
# - Plot the residuals using plot() with a red horizontal line at 0 using abline()
set.seed(123)
n <- 100
# X includes an intercept column plus two random regressors
X <- cbind(1, rnorm(n), rnorm(n))
beta_true <- c(1, 2, -1)  # True coefficients: intercept, beta1, beta2
epsilon <- rnorm(n, mean = 0, sd = 0.5)
y_multi <- X %*% beta_true + epsilon  # Model: y = Xβ + error
# Manual OLS estimation using matrix algebra: β_hat = (X'X)^{-1} X'y
beta_hat_manual <- solve(t(X) %*% X) %*% t(X) %*% y_multi
y_hat_manual <- X %*% beta_hat_manual
residuals_manual <- y_multi - y_hat_manual
plot(residuals_manual, main="Fitted Residuals vs Data", ylab="Fitted Residuals", xlab="Data")
abline(h=0, col="red")
# Install and load necessary packages
if (!require("fredr")) {
install.packages("fredr")
library(fredr)
} else {
library(fredr)
}
if (!require("dplyr")) {
install.packages("dplyr")
library(dplyr)
}
fredr_set_key("aeca492c1d6b24a773fe1fb915779b96") # Replace with your own key from https://cran.r-project.org/web/packages/fredr/vignettes/fredr.html
# Define the observation period
start_date <- as.Date("2015-01-01")
end_date <- as.Date("2020-12-31")
# Download monthly data from FRED
data_PCEC <- fredr(series_id = "PCEC",
observation_start = start_date,
observation_end = end_date)
data_M2SL <- fredr(series_id = "M2SL",
observation_start = start_date,
observation_end = end_date)
data_FEDFUNDS <- fredr(series_id = "FEDFUNDS",
observation_start = start_date,
observation_end = end_date)
# For merging, create a "year-month" column. PCEC and M2SL are monthly; for FEDFUNDS (often daily),
data_PCEC <- data_PCEC %>% mutate(year_month = format(date, "%Y-%m"))
data_M2SL <- data_M2SL %>% mutate(year_month = format(date, "%Y-%m"))
data_FEDFUNDS <- data_FEDFUNDS %>% mutate(year_month = format(date, "%Y-%m"))
# we aggregate to the monthly average.
monthly_FEDFUNDS <- data_FEDFUNDS %>%
group_by(year_month) %>%
summarize(FEDFUNDS = mean(value, na.rm = TRUE))
# Merge the datasets by "year_month"
merged_data <- merge(
data_PCEC[, c("year_month", "value")],
data_M2SL[, c("year_month", "value")],
by = "year_month", suffixes = c("_PCEC", "_M2SL")
)
merged_data <- merge(merged_data, monthly_FEDFUNDS, by = "year_month")
# Rename columns for clarity
names(merged_data) <- c("year_month", "PCEC", "M2SL", "FEDFUNDS")
head(merged_data)
summary(fred_model)
summary(fred_model)
# Convert series to numeric if necessary (just a sanity check)
merged_data$PCEC <- as.numeric(merged_data$PCEC)
merged_data$M2SL <- as.numeric(merged_data$M2SL)
merged_data$FEDFUNDS <- as.numeric(merged_data$FEDFUNDS)
# Manual OLS using matrix algebra for the FRED data example:
# Model: PCEC = β0 + β1*M2SL + β2*FEDFUNDS + error
n_obs <- nrow(merged_data)
X_fred <- cbind(1, merged_data$M2SL, merged_data$FEDFUNDS)  # Intercept + Data
y_fred <- merged_data$PCEC
beta_hat_fred_manual <- solve(t(X_fred) %*% X_fred) %*% t(X_fred) %*% y_fred
y_hat_fred_manual <- X_fred %*% beta_hat_fred_manual
residuals_fred_manual <- y_fred - y_hat_fred_manual
# Fit the same model using lm()
fred_model <- lm(PCEC ~ M2SL + FEDFUNDS, data = merged_data)
cat("Manual OLS Coefficients (FRED data):\n")
print(beta_hat_fred_manual)
cat("\nCoefficients from lm() (FRED data):\n")
print(coef(fred_model))
summary(fred_model)
# Residual vs. Fitted Plot for the FRED model
plot(fred_model$fitted.values, fred_model$residuals,
main = "Residuals vs. Fitted Values",
xlab = "Fitted Values", ylab = "Residuals",
pch = 20, col = "blue")
abline(h = 0, lty = 2, col = "red")
# Q-Q Plot for the residuals
qqnorm(fred_model$residuals, main = "Normal Q-Q Plot")
qqline(fred_model$residuals, col = "red")
